import os
from typing import Dict, List, Optional, Any
from uuid import UUID

from langchain_core.documents import Document
from langchain_core.embeddings import Embeddings
from langchain_openai import OpenAIEmbeddings  # Using OpenAI as an example
from langchain_postgres.vectorstores import PGVector


# --- Configuration ---
# Construct connection string from environment variables set by docker-compose
DB_HOST = os.getenv(
    "POSTGRES_HOST", "localhost"
)  # Default for local dev outside docker
DB_PORT = os.getenv("POSTGRES_PORT", "5432")
DB_USER = os.getenv("POSTGRES_USER", "postgres")
DB_PASSWORD = os.getenv("POSTGRES_PASSWORD", "password")  # Default for local dev
DB_NAME = os.getenv("POSTGRES_DB", "langconnect_dev")  # Default for local dev

CONNECTION_STRING = (
    f"postgresql+psycopg://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}"
)

# Ensure OPENAI_API_KEY is set in your environment for OpenAIEmbeddings
# You can replace OpenAIEmbeddings with your preferred embedding model
DEFAULT_EMBEDDINGS = OpenAIEmbeddings()

DEFAULT_COLLECTION_NAME = "default_collection"

# --- Helper Functions ---


def get_vectorstore(
    collection_name: str = DEFAULT_COLLECTION_NAME,
    embeddings: Embeddings = DEFAULT_EMBEDDINGS,
    connection_string: str = CONNECTION_STRING,
    # mode: str = "async", # langchain-postgres handles async based on driver in conn string
) -> PGVector:
    """Initializes and returns a PGVector store for a specific collection."""
    # Consider adding error handling for connection issues
    store = PGVector(
        collection_name=collection_name,
        connection=connection_string,  # Use connection string directly
        embeddings=embeddings,
        # use_jsonb=True # Store metadata in JSONB - should be default now
    )
    return store


# --- Database Operations using PGVector ---


async def add_documents_to_vectorstore(
    collection_id: str,  # Use collection_id as the collection_name
    documents: List[Document],
    embeddings: Embeddings = DEFAULT_EMBEDDINGS,
    connection_string: str = CONNECTION_STRING,
) -> List[str]:
    """Adds LangChain documents to the specified PGVector collection."""
    store = get_vectorstore(
        collection_name=collection_id,
        embeddings=embeddings,
        connection_string=connection_string,
    )
    # Use aadd_documents for async operation
    # PGVector handles collection creation implicitly on first add
    added_ids = await store.aadd_documents(
        documents, ids=None
    )  # Let PGVector generate IDs
    return added_ids


async def list_documents_in_vectorstore(
    collection_id: str,
    limit: int = 10,
    offset: int = 0,
    connection_string: str = CONNECTION_STRING,
) -> List[Dict[str, Any]]:
    """
    Lists documents (metadata and content) from the vector store's underlying table.
    NOTE: This bypasses LangChain's abstraction for simple listing/pagination.
    Requires direct asyncpg connection to query langchain_pg_embedding table.
    THIS IS A PLACEHOLDER - Needs implementation using direct DB access.
    """
    # This implementation requires direct SQL and knowledge of PGVector's schema.
    # It's less ideal than a built-in LangChain method but necessary for pagination.
    # We need the actual UUID PGVector uses for the collection.

    # TODO: Implement direct asyncpg query for listing/pagination
    # Example (Conceptual - requires asyncpg setup like in connection.py):
    # async with get_db_connection(connection_string) as conn:
    #     # 1. Get collection UUID from langchain_pg_collection where name = collection_id
    #     # 2. Query langchain_pg_embedding table with collection_uuid, limit, offset
    #     query = """
    #         SELECT uuid, document, cmetadata FROM langchain_pg_embedding
    #         WHERE collection_id = (SELECT uuid FROM langchain_pg_collection WHERE name = $1)
    #         ORDER BY uuid -- Or another field if needed
    #         LIMIT $2 OFFSET $3;
    #     """
    #     records = await conn.fetch(query, collection_id, limit, offset)
    #     # Format records into list of dicts matching DocumentResponse structure (ID, content, metadata)
    #     # return formatted_records
    print(
        f"Warning: list_documents_in_vectorstore (collection: {collection_id}) not fully implemented. Returning empty list."
    )
    return []  # Placeholder


async def get_document_from_vectorstore(
    collection_id: str,
    document_id: str,  # This should be the UUID string generated by PGVector
    connection_string: str = CONNECTION_STRING,
) -> Optional[Dict[str, Any]]:
    """
    Gets a single document by its ID from the vector store's underlying table.
    Similar to list_documents, requires direct SQL.
    THIS IS A PLACEHOLDER - Needs implementation using direct DB access.
    """
    # TODO: Implement direct asyncpg query for getting a single document by ID
    # Example (Conceptual):
    # async with get_db_connection(connection_string) as conn:
    #     query = """
    #         SELECT uuid, document, cmetadata FROM langchain_pg_embedding
    #         WHERE uuid = $1;
    #     """
    #     record = await conn.fetchrow(query, UUID(document_id))
    #     # Format record into dict matching DocumentResponse structure
    #     # return formatted_record if record else None
    print(
        f"Warning: get_document_from_vectorstore (collection: {collection_id}, doc: {document_id}) not fully implemented. Returning None."
    )
    return None  # Placeholder


async def delete_documents_from_vectorstore(
    collection_id: str,
    document_ids: List[str],  # List of UUID strings generated by PGVector
    embeddings: Embeddings = DEFAULT_EMBEDDINGS,
    connection_string: str = CONNECTION_STRING,
) -> bool:
    """Deletes documents from the specified PGVector collection by their IDs."""
    if not document_ids:
        return True  # Nothing to delete
    store = get_vectorstore(
        collection_name=collection_id,
        embeddings=embeddings,
        connection_string=connection_string,
    )
    # Use adelete for async operation
    try:
        await store.adelete(ids=document_ids)
        return True
    except Exception as e:
        # Log error appropriately
        print(
            f"Error deleting documents {document_ids} from collection {collection_id}: {e}"
        )
        return False


async def search_documents_in_vectorstore(
    collection_id: str,
    query: str,
    limit: int = 4,  # 'k' for similarity search
    embeddings: Embeddings = DEFAULT_EMBEDDINGS,
    connection_string: str = CONNECTION_STRING,
) -> List[Dict[str, Any]]:
    """Performs semantic similarity search within the specified PGVector collection."""
    store = get_vectorstore(
        collection_name=collection_id,
        embeddings=embeddings,
        connection_string=connection_string,
    )
    # Use asimilarity_search_with_score for async operation and include scores
    # You can also use asimilarity_search if scores are not needed
    results_with_scores = await store.asimilarity_search_with_score(query, k=limit)

    # Format results to match the expected SearchResult structure (content, metadata, score)
    formatted_results = []
    for doc, score in results_with_scores:
        # Try to determine a consistent ID. PGVector uses 'uuid' internally in metadata if not provided.
        doc_id = doc.metadata.get("uuid") or doc.metadata.get("id")
        formatted_results.append(
            {
                # Assuming SearchResult expects these fields
                "id": str(doc_id) if doc_id else None,  # Ensure ID is string
                "page_content": doc.page_content,
                "metadata": doc.metadata,
                "score": score,
            }
        )
    return formatted_results


# --- Helper to convert DB records (if needed elsewhere) ---
def record_to_dict(record) -> Optional[Dict[str, Any]]:
    """Converts an asyncpg Record to a dictionary (useful for direct DB access)."""
    if record is None:
        return None
    # Convert UUIDs to strings and handle potential 'embedding' field if fetched
    return {
        key: (str(value) if isinstance(value, UUID) else value)
        for key, value in record.items()
        if key != "embedding"
    }  # Exclude raw embedding vector
